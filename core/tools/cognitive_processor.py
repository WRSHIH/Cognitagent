import logging
import json
import asyncio
from typing import Dict, Any, Type, List, Union, ClassVar # ğŸ‘ˆ 1. å¾ typing å°å…¥ ClassVar

from pydantic import BaseModel, Field
from langchain_core.tools import BaseTool
from langchain_core.prompts import ChatPromptTemplate
from core.services import get_langchain_gemini_pro

class CognitiveProcessorInput(BaseModel):
    task: str = Field(description="éœ€è¦å°ä¸Šä¸‹æ–‡åŸ·è¡Œçš„å…·é«”ä»»å‹™æè¿°...")
    context: Dict[str, Any] = Field(description="åŒ…å«å…ˆå‰æ‰€æœ‰æ­¥é©Ÿçµæœçš„å­—å…¸...")

class CognitiveProcessorTool(BaseTool):
    """
    ä¸€å€‹ç”¨æ–¼å…§éƒ¨èªçŸ¥è™•ç†çš„å·¥å…·...
    """
    name: str = "CognitiveProcessorTool"
    description: str = (
        "ç•¶ä½ éœ€è¦å°å·²ç¶“è’é›†åˆ°çš„è³‡è¨Šï¼ˆå„²å­˜åœ¨å·¥ä½œè¨˜æ†¶é«”ä¸­ï¼‰é€²è¡Œæ•´ç†ã€åˆ†é¡ã€åˆ†çµ„ã€æ’åºã€ç¸½çµæˆ–æå–é—œéµé»æ™‚ä½¿ç”¨æ­¤å·¥å…·..."
    )

    # --- æœ€çµ‚ä¿®æ­£ï¼šä½¿ç”¨ ClassVar æ¨™è¨˜ ---
    # å‘Šè¨´ Pydantic é€™æ˜¯ä¸€å€‹é¡åˆ¥å±¤ç´šçš„è¨­å®šï¼Œè€Œä¸æ˜¯ä¸€å€‹éœ€è¦é©—è­‰çš„æ¨¡å‹æ¬„ä½ã€‚
    pydantic_args_schema: ClassVar[Type[BaseModel]] = CognitiveProcessorInput

    # ç‚ºäº†æ»¿è¶³æŠ½è±¡é¡åˆ¥çš„åˆç´„ï¼Œæˆ‘å€‘å¿…é ˆå¯¦ç¾ _run
    def _run(self, task: str, context: Dict[str, Any]) -> str:
        try:
            loop = asyncio.get_running_loop()
        except RuntimeError:
            loop = asyncio.new_event_loop()
            asyncio.set_event_loop(loop)
        return loop.run_until_complete(self._arun(task=task, context=context))
        
    async def _arun(self, task: str, context: Dict[str, Any]) -> str:
        # ... (æ­¤è™•çš„æ ¸å¿ƒé‚è¼¯å®Œå…¨ä¿æŒä¸è®Š) ...
        logging.info(f"--- èªçŸ¥è™•ç†å·¥å…·ï¼šé–‹å§‹åŸ·è¡Œä»»å‹™ '{task}' ---")
        if not context:
            return "éŒ¯èª¤ï¼šå·¥ä½œè¨˜æ†¶é«” (context) ç‚ºç©ºï¼Œç„¡æ³•é€²è¡Œè™•ç†ã€‚"

        context_str = json.dumps(context, indent=2, ensure_ascii=False)
        
        prompt_template = ChatPromptTemplate.from_messages([
            ("system", "ä½ æ˜¯ä¸€ä½å°ˆæ¥­çš„è³‡æ–™åˆ†æå¸«..."),
            ("human", """è«‹æ ¹æ“šä»¥ä¸‹ä¸Šä¸‹æ–‡è³‡è¨Š...
             **ä¸Šä¸‹æ–‡ (Context):**\n```json\n{context}\n```
             **ä»»å‹™ (Task):**\n{task}\n
             **ä½ çš„è™•ç†çµæœ:**""")
        ])
        chain = prompt_template | get_langchain_gemini_pro()

        try:
            response = await chain.ainvoke({"context": context_str, "task": task})
            logging.info("--- èªçŸ¥è™•ç†å·¥å…·ï¼šæˆåŠŸå®Œæˆä»»å‹™ ---")
            
            content: Union[str, List[Union[str, Dict]]] = response.content
            if isinstance(content, list):
                text_parts = [part.get("text", "") if isinstance(part, dict) else str(part) for part in content]
                return "\n".join(text_parts)
            
            return str(content)

        except Exception as e:
            logging.error(f"èªçŸ¥è™•ç†å·¥å…·åœ¨åŸ·è¡Œæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}", exc_info=True)
            return f"åœ¨è™•ç†å…§éƒ¨è³‡æ–™æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}"

# å°å‡ºå·¥å…·çš„å¯¦ä¾‹ä»¥ä¾›è¨»å†Š
cognitive_processor_tool = CognitiveProcessorTool()