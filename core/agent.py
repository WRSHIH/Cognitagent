import operator
import logging
from typing import TypedDict, Annotated, List

from langgraph.graph import StateGraph, END
from langgraph.prebuilt import ToolNode
from langgraph.checkpoint.memory import InMemorySaver
from langchain_core.messages import AIMessage, BaseMessage, SystemMessage
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder

# å°å…¥æˆ‘å€‘é›†ä¸­ç®¡ç†çš„ LLM æœå‹™å’Œå·¥å…·åˆ—è¡¨
from core.services import get_langchain_gemini_pro
from core.tool_registry import ALL_TOOLS
from core.utils import load_prompt


# --- 1. å®šç¾© Agent çš„ç‹€æ…‹ (State) ---
class AgentState(TypedDict):
    messages: Annotated[list, operator.add]
    plan: str
    past_steps: Annotated[list, operator.add]
    response: str


# --- 2. å®šç¾©åœ–ä¸­çš„ç¯€é» (Nodes) ---

llm_with_tools = get_langchain_gemini_pro().bind_tools(ALL_TOOLS)
# agent_runnable = prompt | llm_with_tools

def agent_node(state: AgentState) -> dict:

    print("--- Agent æ€è€ƒä¸‹ä¸€æ­¥ ---")
    print(f'State: {state}')
    current_messages = state['messages']
    response_message = llm_with_tools.invoke(current_messages)
    print(f"--- Agent æ±ºç­–: {response_message.content} ---")
    print(f'AI response: {response_message}')

    if response_message.tool_calls: # pyright: ignore[reportAttributeAccessIssue]
        print(f"--- æº–å‚™åŸ·è¡Œå·¥å…·: {response_message.tool_calls}") # pyright: ignore[reportAttributeAccessIssue]

    return {"messages": [response_message]}

def output_node(state: AgentState) -> dict:
    """
    è™•ç†ä¸¦æ ¼å¼åŒ–æœ€çµ‚çš„è¼¸å‡ºã€‚
    """
    print("\n--- æº–å‚™æœ€çµ‚è¼¸å‡º ---")
    last_message = state['messages'][-1]
    
    # å°‡æœ€å¾Œä¸€å‰‡ AI è¨Šæ¯çš„å…§å®¹å­˜å„²åˆ° 'response' æ¬„ä½
    print(f"æœ€çµ‚å›è¦†å…§å®¹: {last_message.content}")
    return {"response": last_message.content}


# å»ºç«‹ä¸€å€‹ ToolNodeï¼Œå®ƒæœƒè‡ªå‹•æ ¹æ“š LLM çš„ tool_calls æŒ‡ä»¤å»åŸ·è¡Œå°æ‡‰çš„å·¥å…·
tool_node = ToolNode(ALL_TOOLS)

# å»ºç«‹æ¢ä»¶åˆ¤æ–·é‚Šçš„é‚è¼¯
def should_continue(state: AgentState) -> str:
    """
    æ¢ä»¶åˆ¤æ–·é‚Š (Conditional Edge)ï¼šæ±ºå®šæµç¨‹æ‡‰è©²çµæŸé‚„æ˜¯ç¹¼çºŒå‘¼å«å·¥å…·ã€‚
    """
    print(f'State: {state}')
    last_message = state['messages'][-1]
    print(f'last msg: {last_message}')
    
    if not last_message.tool_calls:
        print("---ğŸ”š åˆ¤æ–·ï¼šçµæŸæµç¨‹ ---")
        return "end"
    else:
        print("---â¡ï¸ åˆ¤æ–·ï¼šç¹¼çºŒåŸ·è¡Œå·¥å…· ---")
        return "continue"


# --- 3. å»ºç«‹å·¥å» å‡½å¼ (Factory Function) ---
def create_agent_graph():
    logging.info("Initializing Agent Graph...")

    workflow = StateGraph(AgentState)
    workflow.add_node("agent", agent_node)
    workflow.add_node("tools", tool_node)
    workflow.add_node("output", output_node)

    workflow.set_entry_point("agent")

    workflow.add_conditional_edges(
                                    source="agent",
                                    path=should_continue,
                                    path_map={
                                        "continue": "tools",
                                        "end": "output",
                                    },
                                )
    workflow.add_edge("tools", "agent")

    memory = InMemorySaver()
    app = workflow.compile(checkpointer=memory)
    workflow.add_edge("output", END)

    logging.info("âœ… Agent Graph compiled successfully.")

    return app